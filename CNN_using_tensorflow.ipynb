{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this repository, we will be talking more about CNN for classifying images. Using data augmentation, transfer learning and dropout to reduce overfitting and improving accuracy of the model while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the base code from the previous file. We will be building on new concepts using the basics from last file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "  -O /tmp/cats_and_dogs_filtered.zip\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "#train and validation dir are the file path to training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "])\n",
    "#3 convolutions layer and pooling layers \n",
    "#convolution layers find relation between the pixel and surrounding it\n",
    "#pooling finds the largest value from the pixels \n",
    "#these help to capture the features necessary to categorize\n",
    "#activation = 'sigmoid' is used in binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                              validation_data=validation_generator,\n",
    "                              steps_per_epoch=100,\n",
    "                              epochs=15,\n",
    "                              validation_steps=50,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc      = history.history[     'accuracy' ]\n",
    "val_acc  = history.history[ 'val_accuracy' ]\n",
    "loss     = history.history[    'loss' ]\n",
    "val_loss = history.history['val_loss' ]\n",
    "\n",
    "epochs   = range(len(acc)) \n",
    "\n",
    "plt.plot  ( epochs,     acc )\n",
    "plt.plot  ( epochs, val_acc )\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "plt.plot  ( epochs,     loss )\n",
    "plt.plot  ( epochs, val_loss )\n",
    "plt.title ('Training and validation loss'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded=files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "    # predicting images\n",
    "    path='/content/' + fn\n",
    "    img=image.load_img(path, target_size=(150, 150))\n",
    "  \n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "  \n",
    "    classes = model.predict(images, batch_size=10)\n",
    "  \n",
    "    print(classes[0])\n",
    "  \n",
    "    if classes[0]>0:\n",
    "        print(fn + \" is a dog\")\n",
    "    else:\n",
    "        print(fn + \" is a cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an exercise solution to use ImageDataGenerator to get data from the files and train/validate using the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n",
    "# This will require you doing a lot of data preprocessing because\n",
    "# the dataset isn't split into training and validation for you\n",
    "# This code block has all the required inputs\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cats_and_dogs = f\"{getcwd()}/../tmp2/cats-and-dogs.zip\"\n",
    "shutil.rmtree('/tmp')\n",
    "\n",
    "local_zip = path_cats_and_dogs\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
    "print(len(os.listdir('/tmp/PetImages/Dog/')))\n",
    "\n",
    "# Expected Output:\n",
    "# 1500\n",
    "# 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use os.mkdir to create your directories\n",
    "# You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n",
    "try:\n",
    "    os.mkdir('/tmp/cats-v-dogs/')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/cats/')\n",
    "    os.mkdir('/tmp/cats-v-dogs/training/dogs/')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/cats/')\n",
    "    os.mkdir('/tmp/cats-v-dogs/testing/dogs/')\n",
    "    #YOUR CODE GOES HERE\n",
    "    print('na')\n",
    "except OSError:\n",
    "    print('ya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python function called split_data which takes\n",
    "# a SOURCE directory containing the files\n",
    "# a TRAINING directory that a portion of the files will be copied to\n",
    "# a TESTING directory that a portion of the files will be copie to\n",
    "# a SPLIT SIZE to determine the portion\n",
    "# The files should also be randomized, so that the training set is a random\n",
    "# X% of the files, and the test set is the remaining files\n",
    "# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n",
    "# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n",
    "# and 10% of the images will be copied to the TESTING dir\n",
    "# Also -- All images should be checked, and if they have a zero file length,\n",
    "# they will not be copied over\n",
    "#\n",
    "# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n",
    "# os.path.getsize(PATH) gives you the size of the file\n",
    "# copyfile(source, destination) copies a file from source to destination\n",
    "# random.sample(list, len(list)) shuffles a list\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    ls = os.listdir(SOURCE)\n",
    "    random.sample(ls,len(ls))\n",
    "    tra = ls[:int(len(ls)*SPLIT_SIZE)]\n",
    "    tes = ls[int(len(ls)*SPLIT_SIZE):]\n",
    "    for i in tra:\n",
    "        pic = os.path.join(SOURCE,i)\n",
    "        pop = os.path.join(TRAINING,i)\n",
    "        if os.path.getsize(pic):\n",
    "            copyfile(pic,pop)\n",
    "    for i in tes:\n",
    "        pic = os.path.join(SOURCE,i)\n",
    "        pop = os.path.join(TESTING,i)\n",
    "        if os.path.getsize(pic):\n",
    "            copyfile(pic,pop)\n",
    "        \n",
    "        \n",
    "    \n",
    "# YOUR CODE STARTS HERE\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
    "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n",
    "\n",
    "# Expected output:\n",
    "# 1350\n",
    "# 1350\n",
    "# 150\n",
    "# 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
    "# USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu', input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid') \n",
    "# YOUR CODE HERE\n",
    "])\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "TRAINING_DIR = '/tmp/cats-v-dogs/training/'#YOUR CODE HERE\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.0)#YOUR CODE HERE\n",
    "\n",
    "# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n",
    "# TRAIN GENERATOR.\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size = 10,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150,150)\n",
    "                                                   )#YOUR CODE HERE\n",
    "\n",
    "VALIDATION_DIR = '/tmp/cats-v-dogs/testing/'#YOUR CODE HERE\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.0)#YOUR CODE HERE\n",
    "\n",
    "# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n",
    "# VALIDATION GENERATOR.\n",
    "validation_generator =  validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                    batch_size = 10,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150,150)\n",
    "                                                   )#YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "# Expected Output:\n",
    "# Found 2700 images belonging to 2 classes.\n",
    "# Found 300 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT LOSS AND ACCURACY\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "# Desired output. Charts with training and validation metrics. No crash :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code which explains us how to use ImageDataGenerator to apply data augmentation. This type of data augmentation helps us create more data out of the data we already have. This helps us to avoid overfitting the model and improve our models accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                                    rotation_range = 40,\n",
    "                                                    width_shift_range = 0.2,\n",
    "                                                    height_shift_range = 0.2,\n",
    "                                                    shear_range = 0.2,\n",
    "                                                    zoom_range = 0.2,\n",
    "                                                    horizontal_flip = True,\n",
    "                                                    fill_mode = 'nearest' )#YOUR CODE HERE\n",
    "\n",
    "# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE \n",
    "# TRAIN GENERATOR.\n",
    "TRAINING_DIR = '/tmp/cats-v-dogs/training/'#YOUR CODE HERE\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size = 10,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150,150),                                                   \n",
    "                                                   )#YOUR CODE HERE\n",
    "\n",
    "VALIDATION_DIR = '/tmp/cats-v-dogs/testing/'#YOUR CODE HERE\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.0)#YOUR CODE HERE\n",
    "\n",
    "# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE \n",
    "# VALIDATION GENERATOR.\n",
    "validation_generator =  validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                    batch_size = 10,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150,150)\n",
    "                                                   )#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code which guides us on how to use pre-trained weights which has been trained on a bigger dataset. We use these pre-trained weights and add DNN layer to make it specialize with our dataset by training using our dataset. We can do this by either just training the new DNN layer added or by training a few pre-trained layers from the pre-trained model.\n",
    "\n",
    "This code also includes a feature called dropout. Dropout helps us train only a fraction of weights during model training. This prevents us from making a feature(neuron) dominating. This helps in preventing overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "#this copies the pre-trained weights \n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "#this makes all the pre-trained layer untrainable\n",
    "# pre_trained_model.summary()\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "#this combines the pre-trained model and the DNN model \n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a code to for multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = \"/tmp/rps/\"\n",
    "training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "VALIDATION_DIR = \"/tmp/rps-test-set/\"\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "\tTRAINING_DIR,\n",
    "\ttarget_size=(150,150),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=126\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\tVALIDATION_DIR,\n",
    "\ttarget_size=(150,150),\n",
    "\tclass_mode='categorical',\n",
    "  batch_size=126\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=25, steps_per_epoch=20, validation_data = validation_generator, verbose = 1, validation_steps=3)\n",
    "\n",
    "model.save(\"rps.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the final assignment with all the concepts from the course implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "def get_data(filename):\n",
    "  # You will need to write code that will read the file passed\n",
    "  # into this function. The first line contains the column headers\n",
    "  # so you should ignore it\n",
    "  # Each successive line contians 785 comma separated values between 0 and 255\n",
    "  # The first value is the label\n",
    "  # The rest are the pixel values for that picture\n",
    "  # The function will return 2 np.array types. One with all the labels\n",
    "  # One with all the images\n",
    "  #\n",
    "  # Tips: \n",
    "  # If you read a full line (as 'row') then row[0] has the label\n",
    "  # and row[1:785] has the 784 pixel values\n",
    "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
    "  # You are reading in strings, but need the values to be floats\n",
    "  # Check out np.array().astype for a conversion\n",
    "    with open(filename) as training_file:\n",
    "        df = csv.DictReader(training_file)\n",
    "        images = []\n",
    "        labels = []\n",
    "        for row in df:\n",
    "            a = list(dict(row).values())\n",
    "            labels.append(a[0])\n",
    "            images.append(np.array_split(a[1:],28))\n",
    "        \n",
    "        images = np.array(images).astype(float)\n",
    "        labels = np.array(labels).astype(float)\n",
    "      # Your code starts here\n",
    "      # Your code ends here\n",
    "    return images, labels\n",
    "\n",
    "path_sign_mnist_train = f\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\n",
    "path_sign_mnist_test = f\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\n",
    "training_images, training_labels = get_data(path_sign_mnist_train)\n",
    "testing_images, testing_labels = get_data(path_sign_mnist_test)\n",
    "\n",
    "# Keep these\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_images.shape)\n",
    "print(testing_labels.shape)\n",
    "\n",
    "# Their output should be:\n",
    "# (27455, 28, 28)\n",
    "# (27455,)\n",
    "# (7172, 28, 28)\n",
    "# (7172,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section you will have to add another dimension to the data\n",
    "# So, for example, if your array is (10000, 28, 28)\n",
    "# You will need to make it (10000, 28, 28, 1)\n",
    "# Hint: np.expand_dims\n",
    "\n",
    "training_images =  np.expand_dims(training_images, axis=3) # Your Code Here\n",
    "testing_images =  np.expand_dims(testing_images, axis=3)# Your Code Here\n",
    "# Create an ImageDataGenerator and do Image Augmentation\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                  )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "    # Your Code Here)\n",
    "\n",
    "# Keep These\n",
    "print(training_images.shape)\n",
    "print(testing_images.shape)\n",
    "    \n",
    "# Their output should be:\n",
    "# (27455, 28, 28, 1)\n",
    "# (7172, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "# Use no more than 2 Conv2D and 2 MaxPooling2D\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (28,28,1)),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024,activation = 'relu'),\n",
    "                                    tf.keras.layers.Dense(3, activation = 'softmax')])\n",
    "                                    \n",
    "    # Your Code Here\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# Compile Model. \n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'sparse_categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit_generator(train_datagen.flow(training_images, training_labels, batch_size=32), epochs = 2, steps_per_epoch = 20, \n",
    "                                validation_data=validation_datagen.flow(testing_images, testing_labels, batch_size=32), \n",
    "                              verbose =1,validation_steps =10)# Your Code Here (set 'epochs' = 2))\n",
    "\n",
    "model.evaluate(testing_images, testing_labels, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
